{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a639d7b-e089-499b-82be-ee2e6ca0fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from models.transLOB_v2 import TransLOB\n",
    "from utils.preprocessing import create_windows, generate_labels, normalize_features\n",
    "from utils.training import train, validate\n",
    "from utils.loader import LOBDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87320c70-891f-4a7b-a076-55608260b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ca1db-04c2-47a0-a782-767a8d32d0cd",
   "metadata": {},
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2d6e4-5858-4ccd-8f0b-b4c765cf1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = 'data/crypto/'\n",
    "if not os.path.exists(destination) or len(os.listdir(destination)) == 0:\n",
    "    path = kagglehub.dataset_download(\"martinsn/high-frequency-crypto-limit-order-book-data\")\n",
    "    shutil.copytree(path, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd365f89-75ee-4748-9b29-22615a161acc",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b2b38-8ae0-45d0-8c01-cd1a97afe163",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/crypto/BTC_1sec.csv'\n",
    "\n",
    "BATCH_SIZE = 64 # 32\n",
    "WINDOW_SIZE = 100\n",
    "LEVELS = 10\n",
    "HORIZONS=[10, 20, 30, 50, 100]\n",
    "TARGET_HORIZON = 'y_10'\n",
    "LABEL_ALPHA = 2e-5\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "ADAM_B1 = 0.9\n",
    "ADAM_B2 = 0.999\n",
    "WEIGHT_DECAY=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2bbcac-fd3e-48fe-9e83-db72de58c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae07a40-1d39-4cc9-98ea-129d872898c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = data_raw[:300000]\n",
    "data_df['system_time'] = pd.to_datetime(data_df['system_time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a5327-34e6-4419-baac-77895691ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = ['system_time', 'midpoint', 'spread', 'buys', 'sells']\n",
    "distance_features = [f\"{side}_distance_{level}\" for side in ['bids', 'asks'] for level in range(LEVELS)]\n",
    "notional_features = [f\"{side}_notional_{level}\" for side in ['bids', 'asks'] for level in range(LEVELS)]\n",
    "cancel_notional_features = [f\"{side}_cancel_notional_{level}\" for side in ['bids', 'asks'] for level in range(LEVELS)]\n",
    "limit_notional_features = [f\"{side}_limit_notional_{level}\" for side in ['bids', 'asks'] for level in range(LEVELS)]\n",
    "market_notional_features = [f\"{side}_market_notional_{level}\" for side in ['bids', 'asks'] for level in range(LEVELS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52889ff4-113b-4abf-98a8-e1c1b5b7742e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = data_df[meta_features + distance_features + notional_features]\n",
    "data_df = generate_labels(data_df, HORIZONS, alpha=LABEL_ALPHA)\n",
    "data_df = normalize_features(data_df)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582e794-aae1-4d8d-aaa9-28962efb9c13",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b399a5-eec6-47fd-9ece-f45701b35ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_labels = np.array(data_df[TARGET_HORIZON])\n",
    "class_counts = np.bincount(y_val_labels)\n",
    "\n",
    "class_labels = [0, 1, 2]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(class_labels, class_counts)\n",
    "\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Validation Set Class Distribution')\n",
    "plt.xticks(class_labels)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count + 5, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302a347-e714-489c-9d65-318b77f6218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in data_df.columns if col not in meta_features and not col.startswith('y_')]\n",
    "\n",
    "X = data_df[feature_cols].values\n",
    "y = data_df[TARGET_HORIZON].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273abe0-f0ad-43b1-866a-82735933f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_windows, y_labels = create_windows(X, y, WINDOW_SIZE)\n",
    "X_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8ebd2-7e8d-4d2a-bf2c-c8d6576c950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_price_cols = ['bids_distance_0','bids_distance_4','bids_distance_9']\n",
    "ask_price_cols = ['asks_distance_0','asks_distance_4','asks_distance_9']\n",
    "\n",
    "plot_range = 100\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot bids\n",
    "for col in bid_price_cols:\n",
    "    plt.plot(data_df['system_time'][:plot_range], data_df[col].values[:plot_range], label=col)#, color='blue', alpha=0.5)\n",
    "\n",
    "# Plot asks\n",
    "for col in ask_price_cols:\n",
    "    plt.plot(data_df['system_time'][:plot_range], data_df[col].values[:plot_range], label=col)#, color='red', alpha=0.5)\n",
    "\n",
    "plt.title('Bid and Ask Prices over Time')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5eb052-e7c5-41a2-acc5-a95627490a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances = data_df[distance_features].melt(var_name=\"distance_level\", value_name=\"distance_value\")\n",
    "# notionals = data_df[notional_features].melt(var_name=\"notional_level\", value_name=\"notional_value\")\n",
    "\n",
    "# combined = pd.DataFrame({\n",
    "#     \"distance\": distances[\"distance_value\"],\n",
    "#     \"notional\": notionals[\"notional_value\"]\n",
    "# })\n",
    "\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.scatter(combined[\"distance\"], combined[\"notional\"], alpha=0.3)\n",
    "# plt.xlabel('Distance from Midprice')\n",
    "# plt.ylabel('Notional Volume')\n",
    "# plt.title('Price Distance vs Notional Volume')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c59b3-7f17-418c-b157-e7c8d470f9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot mean distance values across levels\n",
    "plt.figure(figsize=(14, 5))\n",
    "data_df[distance_features].mean().plot(kind='bar', title='Mean Scaled Distance Features Across Levels')\n",
    "plt.ylabel('Mean Scaled Distance')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot mean notional values across levels\n",
    "plt.figure(figsize=(14, 5))\n",
    "data_df[notional_features].mean().plot(kind='bar', color='orange', title='Mean Scaled Notional Features Across Levels')\n",
    "plt.ylabel('Mean Scaled Volume')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9d255-57f5-4675-87e0-7c7875fe93d8",
   "metadata": {},
   "source": [
    "## TransLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16a7a4-9323-480a-be2a-20486616a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(X_windows))\n",
    "val_size = int(0.2 * len(X_windows))\n",
    "\n",
    "X_train, y_train = X_windows[:train_size], y_labels[:train_size]\n",
    "X_val, y_val = X_windows[train_size:train_size+val_size], y_labels[train_size:train_size+val_size]\n",
    "X_test, y_test = X_windows[train_size+val_size:], y_labels[train_size+val_size:]\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563c53e-d1eb-4909-8bb0-2c91083e4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LOBDataset(X_train, y_train)\n",
    "val_dataset = LOBDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefde4b-216f-42f9-8b7f-38921cfda948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransLOB(\n",
    "    num_features=len(feature_cols),\n",
    "    num_classes=3,\n",
    "    hidden_channels=14,\n",
    "    d_model=64,\n",
    "    num_heads=3,\n",
    "    num_transformer_blocks=2\n",
    ").to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(ADAM_B1, ADAM_B2), weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1309eb5-a7fd-43cb-b901-d1644aa50475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 15\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss {train_loss:.4f} | Train Acc {train_acc:.4f} | \"\n",
    "          f\"Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), './outputs/transLOB/best_model.pth')\n",
    "        print(f\"âœ… Saved best model at epoch {epoch+1} with Val Acc {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89006b76-f81e-4d67-bff2-2a839a167005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff39eb4-0379-4555-8b90-d9da9a8c051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "X_sample_batch, y_true_batch = next(iter(val_loader))\n",
    "X_sample_batch, y_true_batch = X_sample_batch.to(device), y_true_batch.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_sample_batch)\n",
    "    _, y_pred_batch = outputs.max(1)\n",
    "\n",
    "# Move back to CPU for easy viewing\n",
    "y_true_batch = y_true_batch.cpu().numpy()\n",
    "y_pred_batch = y_pred_batch.cpu().numpy()\n",
    "\n",
    "# Compare true vs predicted\n",
    "for i in range(30):  # first 10 examples\n",
    "    print(f\"Sample {i}: True label = {y_true_batch[i]}, Predicted = {y_pred_batch[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f6ec8-4648-4d43-ac28-47ffb0355229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f144e-22b9-4351-a529-29c05322111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "manual_val_acc = correct / total\n",
    "print(f\"Manual Validation Accuracy: {manual_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a382-f60d-4344-9afe-dd4afc853f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in val_loader:\n",
    "#         X_batch = X_batch.to(device)\n",
    "\n",
    "#         outputs, attn_weights = model(X_batch, return_attention=True)\n",
    "\n",
    "#         # Save attn_weights somewhere\n",
    "#         final_attention = attn_weights\n",
    "#         break  # (Optional) only save first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27692c12-827b-48d4-93f9-9bb061ab8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true_batch, y_pred_batch)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44ce2d-c753-40da-88e6-2dfa0aa1aad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "plt.bar(unique, counts)\n",
    "plt.title(\"Training Label Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d188f-25c7-48a3-8499-e2498e57fd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fd387-6cd5-4dc6-93ca-ca51f5b25349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
